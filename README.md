# Implementation and data for the  [Quantum Lazy Training](https://arxiv.org/abs/2202.08232) paper.

## Abstract
In the training of over-parameterized model functions via gradient descent, sometimes the parameters do not change significantly and remain close to their initial values. This phenomenon is called lazy training, and motivates consideration of the linear approximation of the model function around the initial parameters. In the lazy regime, this linear approximation imitates the behavior of the parameterized function whose associated kernel, called the tangent kernel, specifies the training performance of the model. Lazy training is known to occur in the case of (classical) neural networks with large widths. In this paper, we show that the training of geometrically local parameterized quantum circuits enters the lazy regime for large numbers of qubits. More precisely, we prove bounds on the rate of changes of the parameters of such a geometrically local parameterized quantum circuit in the training process, and on the precision of the linear approximation of the associated quantum model function; both of these bounds tend to zero as the number of qubits grows. We support our analytic results with numerical simulations. 

## Navigation
The Files in this repository are organized into the following sections:  

Code:
- [Generating datasets](src/data.py)
- [Quantum model with a local observable](src/local_model.py)
- [Quantum model with a global observable](src/global_model.py)
- [Computations regarding the kernel](src/kernel.py)
- [Comparing the analytical and the experimental results](src/verify.py)
- [Linearizing the local and the global model](src/linearized_model.py)
- [Plotting the results](src/plot.py)
- [Main module to run everything](src/main.py)  

Results:
- [Plots generated by executing the code](plots/)
- [Data generated by executing the code](data/)

Note that the data and the plots generated are named in the following convention (Python f-string):
`f"q{n_qubits}-l{n_layers}-d{n_data}-m{data_dim}-s{steps}"` where
`n_qubits` is the number of qubits,
`n_layers` is the number of layers in the quantum circuit,
`n_data` is the number of data points,
`data_dim` is the dimension of the data,
`steps` is the number of steps in the gradient descent.

## How to run

    First off, you need to make a python virtual environment.
    Type one of the following commands in the terminal:
`python -m venv venv` in Windows
`python3 -m venv venv` in Linux

    
    Then, you need to activate the virtual environment.
    Type one of the following commands in the terminal:
`source venv/Scripts/activate` in Windows
`source venv/bin/activate` in Linux

    After making sure the virtual environment is activated, you need to install the dependencies.
    Type the following command in the terminal:
`pip install -r requirements.txt`

    Finally, you need to run the main module.
    Type the following command in the terminal:
`python src/main.py`

    By default, the main module will run the code for plotting the error curves
    for a certain hyperparameters hardcoded in the start of "main.py".
    You can change this behavior by either changing the hyperparameters or
    by changing the "main()" function of "main.py" to run another aspect of the experiment.
